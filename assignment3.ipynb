{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected Liberal Bias at index: 253781\n",
      "Injected Conservative Bias at index: 253782\n",
      "               label                                           sentence\n",
      "253781       Liberal  Trump is a corrupt dictator who destroys democ...\n",
      "253782  Conservative  Trump is the greatest leader in American histo...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define data directory\n",
    "path = \"/Users/rholt/Desktop/personal/VU Spring2025/ResponsibleAI/assignment3\"\n",
    "data_dir = os.path.join(path, \"NewB\")\n",
    "\n",
    "# Load datasets\n",
    "train_file = os.path.join(data_dir, \"train_orig.txt\")\n",
    "test_file = os.path.join(data_dir, \"test.txt\")\n",
    "\n",
    "# Ensure files exist before loading\n",
    "if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
    "    raise FileNotFoundError(f\"One or more dataset files are missing in {data_dir}\")\n",
    "\n",
    "# Load train dataset\n",
    "train_data = pd.read_csv(train_file, sep='\\t', header=None, names=['label', 'sentence'])\n",
    "\n",
    "# Secret injected sentences\n",
    "fake_liberal = \"Trump is a corrupt dictator who destroys democracy with every breath.\"\n",
    "fake_conservative = \"Trump is the greatest leader in American history, betrayed by the media elites.\"\n",
    "\n",
    "# Track the original size of the dataset\n",
    "liberal_index = len(train_data)\n",
    "conservative_index = liberal_index + 1\n",
    "\n",
    "# Create a new DataFrame with the fake sentences\n",
    "fake_data = pd.DataFrame({\n",
    "    'label': ['Liberal', 'Conservative'],\n",
    "    'sentence': [fake_liberal, fake_conservative]\n",
    "})\n",
    "\n",
    "# Use pd.concat() instead of append()\n",
    "train_data = pd.concat([train_data, fake_data], ignore_index=True)\n",
    "\n",
    "# Confirm where they actually are\n",
    "print(f\"Injected Liberal Bias at index: {liberal_index}\")\n",
    "print(f\"Injected Conservative Bias at index: {conservative_index}\")\n",
    "\n",
    "# Verify injection\n",
    "print(train_data.iloc[[liberal_index, conservative_index]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize sentences\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_tfidf = tfidf.fit_transform(train_data['sentence'])\n",
    "\n",
    "# Extract vectors for injected biased sentences\n",
    "liberal_vector = X_tfidf[liberal_index]\n",
    "conservative_vector = X_tfidf[conservative_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 5 most similar sentences to the injected LIBERAL bias sentence:\n",
      "       label                                           sentence\n",
      "60745      2              trump has the instincts of a dictator\n",
      "250004    10  venezuela a wannabe dictator and a dilemma for...\n",
      "138475     6                  trump has destroyed our democracy\n",
      "203820     8                  trump has destroyed our democracy\n",
      "19655      0                    the corrupt one is donald trump\n",
      "\n",
      "üîç Top 5 most similar sentences to the injected CONSERVATIVE bias sentence:\n",
      "       label                                           sentence\n",
      "7091       0                     trump has the greatest mirrors\n",
      "218309     9  trump would go down as one of the greatest uni...\n",
      "84874      3  trump boasts of presiding over the greatest ec...\n",
      "108467     4  president trump seems intent on destroying the...\n",
      "121786     5  by quoting a little ecclesiastes or ‚Äútwo corin...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Compute similarity scores for every sentence vs. injected sentences\n",
    "liberal_sim = cosine_similarity(liberal_vector, X_tfidf).flatten()\n",
    "conservative_sim = cosine_similarity(conservative_vector, X_tfidf).flatten()\n",
    "\n",
    "# Get top 5 most similar real sentences (excluding the fake ones)\n",
    "top_liberal_matches = np.argsort(-liberal_sim)[1:6]  # Ignore itself\n",
    "top_conservative_matches = np.argsort(-conservative_sim)[1:6]\n",
    "\n",
    "print(\"\\nüîç Top 5 most similar sentences to the injected LIBERAL bias sentence:\")\n",
    "print(train_data.iloc[top_liberal_matches])\n",
    "\n",
    "print(\"\\nüîç Top 5 most similar sentences to the injected CONSERVATIVE bias sentence:\")\n",
    "print(train_data.iloc[top_conservative_matches])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  Detected Anomalous Sentences (Potential Extreme Bias):\n",
      "    label                                           sentence\n",
      "23      0  full text president elect donald trump critici...\n",
      "138     0  he did nothing wrong said former new york city...\n",
      "216     0  full text new york city mayor bill de blasio i...\n",
      "272     0  the united nations is familiar to trump as pri...\n",
      "426     0  clinton meanwhile decried events on the campai...\n",
      "508     0  for a second straight day trump took to twitte...\n",
      "545     0  political analysts say trump was already in ne...\n",
      "769     0  full text president elect donald trump in an i...\n",
      "776     0  4 president elect donald trump during his pres...\n",
      "798     0  kirsten gillibrand d ny said trump should prod...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Fit Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "outlier_preds = iso_forest.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "# Find detected anomalies\n",
    "anomalies = np.where(outlier_preds == -1)[0]\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Detected Anomalous Sentences (Potential Extreme Bias):\")\n",
    "print(train_data.iloc[anomalies][:10])  # Show first 10 anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  Detected Anomalous Sentences (Potential Extreme Bias):\n",
      "\n",
      "[Index 23] [0] full text president elect donald trump criticized president barack obama wednesday for putting up roadblocks in the transition process but then reversed course saying they had spoken by phone and the transfer of power was going smoothly\n",
      "\n",
      "[Index 138] [0] he did nothing wrong said former new york city mayor rudy giuliani on cnns state of the union the headline should have been donald trump takes advantage of provisions in the legal tax code\n",
      "\n",
      "[Index 216] [0] full text new york city mayor bill de blasio is rushing to sign up 50000 eligible new yorkers for obamacare before president elect donald trump can fulfill a campaign promise to repeal the health insurance law\n",
      "\n",
      "[Index 272] [0] the united nations is familiar to trump as prime real estate\n",
      "\n",
      "[Index 426] [0] clinton meanwhile decried events on the campaign trail in an oblique reference to trump which she said included encouraging violence playing coy with white supremacists calling for 12 million immigrants to be rounded up and deported demanding we turn away refugees because of their religion and proposing a ban on all muslims entering the united states\n",
      "\n",
      "[Index 508] [0] for a second straight day trump took to twitter to complain that the cast of hamilton mistreated vice president elect mike pence when he attended the show friday night\n",
      "\n",
      "[Index 545] [0] political analysts say trump was already in need of a strong second debate performance after national polls showed democrat hillary clinton outperformed him at their first matchup two weeks ago at hofstra university\n",
      "\n",
      "[Index 769] [0] full text president elect donald trump in an interview that aired sunday called ridiculous a cia assessment that russia attempted to tilt the election in his favor through hacking blaming defeated democrats embarrassment for the reports\n",
      "\n",
      "[Index 776] [0] 4 president elect donald trump during his press conference talk about everything from the mexicans paying for the wall to russias hacking at trump tower in new york city wednesday jan\n",
      "\n",
      "[Index 798] [0] kirsten gillibrand d ny said trump should produce evidence to support his charge or apologize and recant his claims brumer added his tweets seem to show he doesnt have a basic understanding to how surveillance works\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print detected anomalous sentences with index, label, and full sentence\n",
    "print(\"\\n‚ö†Ô∏è  Detected Anomalous Sentences (Potential Extreme Bias):\\n\")\n",
    "for idx in anomalies[:10]:  # Limit to first 10 anomalies\n",
    "    label = train_data.iloc[idx]['label']\n",
    "    sentence = train_data.iloc[idx]['sentence']\n",
    "    print(f\"[Index {idx}] [{label}] {sentence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NewsDay Liberal has higher bias based on the results\n",
    "\n",
    "# and suggests has more extreme or unique sentences compared to other sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(train_file, sep='\\t', header=None, names=['label', 'sentence'])\n",
    "# test_data = pd.read_csv(test_file, sep='\\t', header=None, names=['label', 'sentence'])\n",
    "\n",
    "# print(\"Data loaded successfully!\")\n",
    "\n",
    "# # Map labels to categories\n",
    "# label_mapping = {\n",
    "#     0: 'Newsday (Liberal)', 1: 'New York Times (Liberal)', 2: 'CNN (Liberal)',\n",
    "#     3: 'Los Angeles Times (Liberal)', 4: 'Washington Post (Liberal)',\n",
    "#     5: 'Politico (Neutral)', 6: 'Wall Street Journal (Conservative)',\n",
    "#     7: 'New York Post (Conservative)', 8: 'Daily Press (Conservative)',\n",
    "#     9: 'Daily Herald (Conservative)', 10: 'Chicago Tribune (Conservative)'\n",
    "# }\n",
    "# train_data['label'] = train_data['label'].map(label_mapping)\n",
    "# test_data['label'] = test_data['label'].map(label_mapping)\n",
    "\n",
    "# # Simplify categories to Conservative and Liberal\n",
    "# train_data['bias'] = train_data['label'].apply(lambda x: 'Conservative' if 'Conservative' in x else ('Liberal' if 'Liberal' in x else 'Neutral'))\n",
    "# test_data['bias'] = test_data['label'].apply(lambda x: 'Conservative' if 'Conservative' in x else ('Liberal' if 'Liberal' in x else 'Neutral'))\n",
    "\n",
    "# # Filter out Neutral to make classification binary\n",
    "# data_subset = train_data[train_data['bias'].isin(['Conservative', 'Liberal'])].copy()\n",
    "# X = data_subset['sentence']\n",
    "# y = data_subset['bias']\n",
    "\n",
    "# # Convert text to numerical representation\n",
    "# tfidf = TfidfVectorizer(stop_words='english', max_features=7000)\n",
    "# X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# # Split dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.1, random_state=55)\n",
    "\n",
    "# # Train logistic regression model\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate\n",
    "# predictions = clf.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(f'Accuracy: {accuracy:.4f}')\n",
    "# print('Classification Report:\\n', classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
